# Luozhen计划

目前想到以下两点

1. 特征

   本来以为分本分类的特征就是分词之后所形成的词向量, 但现在觉得可能有点狭隘了, 如果仅仅以分词或做了简单处理后作为特征, 有点太瞎折腾了......

   * 深入英文分词, 参见["英文分词_luozhen"](./英文分词_luozhen) 这篇, 探索一下. 当然可以先一开始做出个大致的东西, 日后再优化~
   * 想到可以用模型选择特征`特征选择 特征提取` , 因为文本的特征可能对分类有明显的偏好, 这里所说的偏好, 个人是指某个词的出现对分类具有很大影响, 或相关性. 虽然0820meeting说词貌似与分类不存在强相关.....(暂定)
   * 特征提取, 试试机器学习算法将本文向量转化为等长的向量(使用且不限于上次使用的word2vec)

2. 模型

   模型在0820meeting上, 注意到老周你说xgboost效果好, 个人也想试试, 但是更想试试CNN, 因为恰好自己现在工作上接触到文本的CNN, 所以想试试

   * CNN/DNN的尝试

   * xgboost(暂定)

总而言之, 现在的想法是大致能搞出个模型, 在之后再根据他人或自己的分析, 尝试其他方面. 

### 0827
想法总是提前于实践, 觉得自己有好多想法, 但是实践起来异常困难. 后知后觉的人.....
这一周, 除了TensorFlow入门, 貌似目前木有任何进展
看了些博客, 但是理解不透彻...

---

## 9月份计划
### 7-10号:
1. 知乎CNN链接, 学习完
2. 参考kaggle人家CNN经验(word2vec, LSTM, RNN, doc2vec)
### 11-17号:
1. 调参
2. 分析数据, 特征挖掘
3. 模型优化(RNN, DNN)
4. 特征处理一块.....(待续)
### 18-24号:
因为目前对CNN, RNN了解不深刻, 暂时木有太多想法. 想法能比较直观的是特征方面, 不过也可能不适用深度学习. 需自行了解. 此处计划后续加入.